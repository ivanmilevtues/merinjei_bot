Date: Sun Dec 24 19:00:56 2017
Time taken to train: 1.7427499294281006 seconds
Classifier: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
---------------------------------
Test Accuracy   : 0.9147583980631494
Train Accuracy  : 0.9605891452014258
---------------------------------
Test precision  : 0.592069761981788
Train precision : 0.7939219184152745
---------------------------------
Test recall     : 0.6136890951276102
Train recall    : 0.8085280852808528
---------------------------------
Test f1         : 0.7146234380276932
Train f1        : 0.8706401766004417
==============================================
Date: Sun Dec 24 19:01:08 2017
Time taken to train: 3.6305489540100098 seconds
Classifier: GaussianNB(priors=None)
---------------------------------
Test Accuracy   : 0.7622314132956723
Train Accuracy  : 0.894814715179232
---------------------------------
Test precision  : 0.2904072956848476
Train precision : 0.6092930302273295
---------------------------------
Test recall     : 0.570185614849188
Train recall    : 1.0
---------------------------------
Test f1         : 0.4547767753874624
Train f1        : 0.7572182552002483
==============================================
Date: Sun Dec 24 19:02:25 2017
Time taken to train: 75.1136999130249 seconds
Classifier: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
---------------------------------
Test Accuracy   : 0.8866135377786745
Train Accuracy  : 0.9995964758894343
---------------------------------
Test precision  : 0.518312162347073
Train precision : 0.9979434995103197
---------------------------------
Test recall     : 0.701276102088167
Train recall    : 0.997539975399754
---------------------------------
Test f1         : 0.6826651609260305
Train f1        : 0.9987684729064039
==============================================
Date: Sun Dec 24 19:02:49 2017
Time taken to train: 23.206650018692017 seconds
Classifier: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
---------------------------------
Test Accuracy   : 0.8648239685261777
Train Accuracy  : 0.9906516914385635
---------------------------------
Test precision  : 0.3589594765723934
Train precision : 0.9519605986920584
---------------------------------
Test recall     : 0.2906032482598608
Train recall    : 0.9454694546945469
---------------------------------
Test f1         : 0.42783945345858243
Train f1        : 0.970743001473374
==============================================
Date: Sun Dec 24 19:10:04 2017
Time taken to train: 423.68222999572754 seconds
Classifier: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
---------------------------------
Test Accuracy   : 0.9081004741248865
Train Accuracy  : 0.9387315892124555
---------------------------------
Test precision  : 0.5944695416884387
Train precision : 0.6917989011197566
---------------------------------
Test recall     : 0.7679814385150812
Train recall    : 0.8118081180811808
---------------------------------
Test f1         : 0.7440292216914863
Train f1        : 0.8129747485115992
==============================================
Date: Sun Dec 24 19:13:51 2017
Time taken to train: 132.40489864349365 seconds
Classifier: BaggingClassifier(base_estimator=None, bootstrap=True,
         bootstrap_features=False, max_features=1.0, max_samples=1.0,
         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,
         verbose=0, warm_start=False)
---------------------------------
Test Accuracy   : 0.9140522546151518
Train Accuracy  : 0.9948214405810747
---------------------------------
Test precision  : 0.5958377127203071
Train precision : 0.9729529161301506
---------------------------------
Test recall     : 0.6722737819025522
Train recall    : 0.972529725297253
---------------------------------
Test f1         : 0.7312302839116719
Train f1        : 0.9840282099149555
==============================================
Date: Sun Dec 24 19:45:04 2017
Time taken to train: 1871.2150180339813 seconds
Classifier: GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              presort='auto', random_state=None, subsample=1.0, verbose=0,
              warm_start=False)
---------------------------------
Test Accuracy   : 0.9054776556037526
Train Accuracy  : 0.9320061873696953
---------------------------------
Test precision  : 0.549910674619833
Train precision : 0.6487247512518167
---------------------------------
Test recall     : 0.5678654292343387
Train recall    : 0.6514965149651496
---------------------------------
Test f1         : 0.6763385146804836
Train f1        : 0.7586536166149439
==============================================
Date: Sun Dec 24 19:55:11 2017
Time taken to train: 604.7098784446716 seconds
Classifier: GridSearchCV(cv=None, error_score='raise',
       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False),
       fit_params=None, iid=True, n_jobs=1,
       param_grid={'n_estimators': [10, 30, 50, 100], 'criterion': ['gini', 'entropy'], 'n_jobs': [-1]},
       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,
       scoring=None, verbose=0)
---------------------------------
Test Accuracy   : 0.8849994956118229
Train Accuracy  : 0.9995964758894343
---------------------------------
Test precision  : 0.4510583916810949
Train precision : 0.9977432503852952
---------------------------------
Test recall     : 0.39675174013921116
Train recall    : 0.998769987699877
---------------------------------
Test f1         : 0.5454545454545454
Train f1        : 0.998769987699877
==============================================
Date: Mon Dec 25 19:38:33 2017
Time taken to train: 2.6165318489074707 seconds
Classifier: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
---------------------------------
Test Accuracy   : 0.9155654191465752
Train Accuracy  : 0.9603201291277154
---------------------------------
Test precision  : 0.5958487396888617
Train precision : 0.7922245042038072
---------------------------------
Test recall     : 0.6189095127610209
Train recall    : 0.8134481344813448
---------------------------------
Test f1         : 0.7182766745203635
Train f1        : 0.8705572619569987
==============================================
Date: Mon Dec 25 19:38:46 2017
Time taken to train: 4.181003093719482 seconds
Classifier: GaussianNB(priors=None)
---------------------------------
Test Accuracy   : 0.7906789064864319
Train Accuracy  : 0.9020781491694129
---------------------------------
Test precision  : 0.3289059122814015
Train precision : 0.6261874197689346
---------------------------------
Test recall     : 0.6090487238979119
Train recall    : 1.0
---------------------------------
Test f1         : 0.502994011976048
Train f1        : 0.7701294600568361
==============================================
Date: Mon Dec 25 19:40:23 2017
Time taken to train: 95.01912760734558 seconds
Classifier: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
---------------------------------
Test Accuracy   : 0.8894381115706648
Train Accuracy  : 0.9997309839262896
---------------------------------
Test precision  : 0.525300447035909
Train precision : 0.9986289996735465
---------------------------------
Test recall     : 0.7001160092807425
Train recall    : 0.998359983599836
---------------------------------
Test f1         : 0.6877492877492878
Train f1        : 0.9991793188346327
==============================================
Date: Mon Dec 25 19:40:52 2017
Time taken to train: 27.684523820877075 seconds
Classifier: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
---------------------------------
Test Accuracy   : 0.8606879854736205
Train Accuracy  : 0.9899118972358598
---------------------------------
Test precision  : 0.34085012536307835
Train precision : 0.948190378313918
---------------------------------
Test recall     : 0.2708816705336427
Train recall    : 0.940959409594096
---------------------------------
Test f1         : 0.4034557235421166
Train f1        : 0.9683544303797469
==============================================
Date: Mon Dec 25 19:50:44 2017
Time taken to train: 578.9586148262024 seconds
Classifier: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
---------------------------------
Test Accuracy   : 0.9160698073237163
Train Accuracy  : 0.9367139686596274
---------------------------------
Test precision  : 0.6092121656878351
Train precision : 0.6788661408655886
---------------------------------
Test recall     : 0.7117169373549884
Train recall    : 0.7761377613776138
---------------------------------
Test f1         : 0.7468046256847231
Train f1        : 0.8009308229320923
==============================================
Date: Mon Dec 25 19:54:47 2017
Time taken to train: 139.95822143554688 seconds
Classifier: BaggingClassifier(base_estimator=None, bootstrap=True,
         bootstrap_features=False, max_features=1.0, max_samples=1.0,
         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,
         verbose=0, warm_start=False)
---------------------------------
Test Accuracy   : 0.9118329466357309
Train Accuracy  : 0.9950904566547851
---------------------------------
Test precision  : 0.5909335600427763
Train precision : 0.9738239761769751
---------------------------------
Test recall     : 0.691415313225058
Train recall    : 0.977449774497745
---------------------------------
Test f1         : 0.7317372621240025
Train f1        : 0.9849204709770709
==============================================
Date: Mon Dec 25 20:28:01 2017
Time taken to train: 1992.089189529419 seconds
Classifier: GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              presort='auto', random_state=None, subsample=1.0, verbose=0,
              warm_start=False)
---------------------------------
Test Accuracy   : 0.9059820437808938
Train Accuracy  : 0.9320061873696953
---------------------------------
Test precision  : 0.5521145742705567
Train precision : 0.6487322206733368
---------------------------------
Test recall     : 0.5696055684454756
Train recall    : 0.6531365313653137
---------------------------------
Test f1         : 0.6781767955801106
Train f1        : 0.7591136526090064
==============================================
Date: Mon Dec 25 20:39:56 2017
Time taken to train: 712.3323681354523 seconds
Classifier: GridSearchCV(cv=None, error_score='raise',
       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False),
       fit_params=None, iid=True, n_jobs=1,
       param_grid={'n_estimators': [10, 30, 50, 100], 'criterion': ['gini', 'entropy'], 'n_jobs': [-1]},
       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,
       scoring=None, verbose=0)
---------------------------------
Test Accuracy   : 0.8778371834964188
Train Accuracy  : 0.9997309839262896
---------------------------------
Test precision  : 0.4170530963846772
Train precision : 0.9984951640501395
---------------------------------
Test recall     : 0.339907192575406
Train recall    : 0.999179991799918
---------------------------------
Test f1         : 0.49181703734788085
Train f1        : 0.999179991799918
==============================================
Date: Fri Dec 29 00:26:05 2017
Time taken to train: 3.3784987926483154 seconds
Classifier: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
---------------------------------
Test Accuracy   : 0.915464541511147
Train Accuracy  : 0.960387383146143
---------------------------------
Test precision  : 0.5954244030436593
Train precision : 0.7925473763634024
---------------------------------
Test recall     : 0.6189095127610209
Train recall    : 0.8142681426814268
---------------------------------
Test f1         : 0.7180349932705249
Train f1        : 0.8708616531462398
==============================================
Date: Fri Dec 29 00:26:17 2017
Time taken to train: 3.6360015869140625 seconds
Classifier: GaussianNB(priors=None)
---------------------------------
Test Accuracy   : 0.7910824170281449
Train Accuracy  : 0.9013383549667092
---------------------------------
Test precision  : 0.3326335819170074
Train precision : 0.6244239631336406
---------------------------------
Test recall     : 0.6194895591647331
Train recall    : 1.0
---------------------------------
Test f1         : 0.5077252198716425
Train f1        : 0.7687943262411348
==============================================
Date: Fri Dec 29 00:27:25 2017
Time taken to train: 67.26507043838501 seconds
Classifier: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
---------------------------------
Test Accuracy   : 0.8911530313729447
Train Accuracy  : 0.9997309839262896
---------------------------------
Test precision  : 0.5356301038547558
Train precision : 0.9986289996735465
---------------------------------
Test recall     : 0.7221577726218097
Train recall    : 0.998359983599836
---------------------------------
Test f1         : 0.6976744186046511
Train f1        : 0.9991793188346327
==============================================
Date: Fri Dec 29 00:27:50 2017
Time taken to train: 23.15856146812439 seconds
Classifier: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
---------------------------------
Test Accuracy   : 0.8705739937455866
Train Accuracy  : 0.9913914856412671
---------------------------------
Test precision  : 0.3857328658022334
Train precision : 0.9558618023135825
---------------------------------
Test recall     : 0.32830626450116007
Train recall    : 0.949159491594916
---------------------------------
Test f1         : 0.4687370600414079
Train f1        : 0.9730979403110551
==============================================
Date: Fri Dec 29 00:36:47 2017
Time taken to train: 524.8418583869934 seconds
Classifier: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
---------------------------------
Test Accuracy   : 0.9160698073237163
Train Accuracy  : 0.9367139686596274
---------------------------------
Test precision  : 0.6092121656878351
Train precision : 0.6788661408655886
---------------------------------
Test recall     : 0.7117169373549884
Train recall    : 0.7761377613776138
---------------------------------
Test f1         : 0.7468046256847231
Train f1        : 0.8009308229320923
==============================================
Date: Fri Dec 29 00:40:19 2017
Time taken to train: 122.81123900413513 seconds
Classifier: BaggingClassifier(base_estimator=None, bootstrap=True,
         bootstrap_features=False, max_features=1.0, max_samples=1.0,
         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,
         verbose=0, warm_start=False)
---------------------------------
Test Accuracy   : 0.9094118833854534
Train Accuracy  : 0.9956957428206336
---------------------------------
Test precision  : 0.5807547343889208
Train precision : 0.9767868239899777
---------------------------------
Test recall     : 0.6809744779582366
Train recall    : 0.981959819598196
---------------------------------
Test f1         : 0.7233518176216881
Train f1        : 0.9868149979398434
==============================================
Date: Fri Dec 29 01:08:10 2017
Time taken to train: 1669.642015695572 seconds
Classifier: GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              presort='auto', random_state=None, subsample=1.0, verbose=0,
              warm_start=False)
---------------------------------
Test Accuracy   : 0.9052759003328962
Train Accuracy  : 0.932073441388123
---------------------------------
Test precision  : 0.5488677459563438
Train precision : 0.6490653998433106
---------------------------------
Test recall     : 0.5655452436194895
Train recall    : 0.6523165231652317
---------------------------------
Test f1         : 0.6749740394600208
Train f1        : 0.7590648854961833
==============================================
Date: Fri Dec 29 01:16:17 2017
Time taken to train: 484.9506561756134 seconds
Classifier: GridSearchCV(cv=None, error_score='raise',
       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False),
       fit_params=None, iid=True, n_jobs=1,
       param_grid={'n_estimators': [10, 30, 50, 100], 'criterion': ['gini', 'entropy'], 'n_jobs': [-1]},
       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,
       scoring=None, verbose=0)
---------------------------------
Test Accuracy   : 0.8731968122667205
Train Accuracy  : 0.9990584437420136
---------------------------------
Test precision  : 0.39602723080109936
Train precision : 0.995134413773513
---------------------------------
Test recall     : 0.3254060324825986
Train recall    : 0.994669946699467
---------------------------------
Test f1         : 0.47162673392181587
Train f1        : 0.9971228935470612
==============================================
Date: Sat Dec 30 19:09:47 2017
Time taken to train: 16.04547643661499 seconds
Classifier: GridSearchCV(cv=<generator object _BaseKFold.split at 0x000001F4FFC4C150>,
       error_score='raise',
       estimator=Pipeline(memory=None,
     steps=[('select', SelectFromModel(estimator=LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, wa...ty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))]),
       fit_params=None, iid=True, n_jobs=1, param_grid=[{}],
       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,
       scoring=None, verbose=2)
---------------------------------
Test Accuracy   : 0.6716432966811258
Train Accuracy  : 0.7463178424910888
---------------------------------
Test precision  : 0.3259025852963107
Train precision : 0.37682922208885117
---------------------------------
Test recall     : 0.9263341067285383
Train recall    : 0.949159491594916
---------------------------------
Test f1         : 0.49527058458675766
Train f1        : 0.5510592716019995
=======================
Date: Fri Jan  5 20:38:40 2018
Time taken to train: 5.286388158798218 seconds
Classifier: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.94      0.95      0.95      8145
          1       0.76      0.74      0.75      1768

avg / total       0.91      0.91      0.91      9913

Train:
             precision    recall  f1-score   support

          0       1.00      1.00      1.00     12429
          1       1.00      1.00      1.00      2440

avg / total       1.00      1.00      1.00     14869

==============================================
Date: Fri Jan  5 20:38:50 2018
Time taken to train: 3.354702949523926 seconds
Classifier: GaussianNB(priors=None)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.85      0.89      0.87      7748
          1       0.52      0.42      0.46      2165

avg / total       0.77      0.79      0.78      9913

Train:
             precision    recall  f1-score   support

          0       0.90      1.00      0.95     11229
          1       1.00      0.67      0.80      3640

avg / total       0.93      0.92      0.91     14869

==============================================
Date: Fri Jan  5 20:40:39 2018
Time taken to train: 107.39478850364685 seconds
Classifier: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.93      0.92      0.92      8206
          1       0.64      0.64      0.64      1707

avg / total       0.88      0.88      0.88      9913

Train:
             precision    recall  f1-score   support

          0       1.00      1.00      1.00     12434
          1       1.00      1.00      1.00      2435

avg / total       1.00      1.00      1.00     14869

==============================================
Date: Fri Jan  5 20:40:54 2018
Time taken to train: 14.254605531692505 seconds
Classifier: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.99      0.86      0.92      9466
          1       0.21      0.81      0.33       447

avg / total       0.95      0.85      0.89      9913

Train:
             precision    recall  f1-score   support

          0       1.00      0.99      0.99     12564
          1       0.94      1.00      0.97      2305

avg / total       0.99      0.99      0.99     14869

==============================================
Date: Fri Jan  5 20:48:18 2018
Time taken to train: 430.94112038612366 seconds
Classifier: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.95      0.93      0.94      8436
          1       0.64      0.75      0.69      1477

avg / total       0.91      0.90      0.90      9913

Train:
             precision    recall  f1-score   support

          0       0.96      0.95      0.96     12505
          1       0.76      0.78      0.77      2364

avg / total       0.93      0.92      0.93     14869

==============================================
Date: Fri Jan  5 20:54:08 2018
Time taken to train: 228.3321886062622 seconds
Classifier: BaggingClassifier(base_estimator=None, bootstrap=True,
         bootstrap_features=False, max_features=1.0, max_samples=1.0,
         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,
         verbose=0, warm_start=False)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.95      0.92      0.93      8445
          1       0.61      0.71      0.65      1468

avg / total       0.90      0.89      0.89      9913

Train:
             precision    recall  f1-score   support

          0       1.00      0.99      1.00     12508
          1       0.96      0.99      0.98      2361

avg / total       0.99      0.99      0.99     14869

==============================================
Date: Fri Jan  5 21:28:56 2018
Time taken to train: 2086.0732502937317 seconds
Classifier: GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              presort='auto', random_state=None, subsample=1.0, verbose=0,
              warm_start=False)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.98      0.90      0.94      8899
          1       0.49      0.84      0.62      1014

avg / total       0.93      0.90      0.91      9913

Train:
             precision    recall  f1-score   support

          0       0.98      0.93      0.96     13198
          1       0.61      0.89      0.72      1671

avg / total       0.94      0.92      0.93     14869

==============================================
Date: Sun Jan  7 01:08:10 2018
Time taken to train: 0.8355557918548584 seconds
Classifier: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       1.00      1.00      1.00        13
          1       1.00      1.00      1.00       248
          2       0.33      1.00      0.50         1
          3       0.98      0.97      0.97       289
          4       0.97      0.95      0.96       188
          5       0.98      0.96      0.97       229
          6       0.50      0.90      0.64        10
          7       0.00      0.00      0.00         0

avg / total       0.98      0.97      0.97       978

Train:
             precision    recall  f1-score   support

          0       1.00      1.00      1.00        73
          1       1.00      1.00      1.00       915
          2       1.00      1.00      1.00         6
          3       1.00      0.99      1.00      1151
          4       1.00      1.00      1.00       842
          5       1.00      1.00      1.00       865
          6       0.93      1.00      0.97        57
          7       1.00      1.00      1.00         5

avg / total       1.00      1.00      1.00      3914

==============================================
Date: Sun Jan  7 01:08:15 2018
Time taken to train: 0.55950927734375 seconds
Classifier: GaussianNB(priors=None)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.77      1.00      0.87        10
          1       0.85      0.76      0.80       277
          2       0.33      1.00      0.50         1
          3       0.63      0.78      0.70       233
          4       0.64      0.58      0.61       204
          5       0.81      0.76      0.78       242
          6       0.39      0.64      0.48        11
          7       0.00      0.00      0.00         0

avg / total       0.74      0.73      0.73       978

Train:
             precision    recall  f1-score   support

          0       1.00      1.00      1.00        73
          1       1.00      0.97      0.99       939
          2       1.00      1.00      1.00         6
          3       0.94      1.00      0.97      1080
          4       0.99      0.94      0.97       889
          5       0.98      0.98      0.98       861
          6       1.00      1.00      1.00        61
          7       1.00      1.00      1.00         5

avg / total       0.98      0.98      0.98      3914

==============================================
Date: Sun Jan  7 01:08:20 2018
Time taken to train: 4.564074516296387 seconds
Classifier: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
---------------------------------
Test:
             precision    recall  f1-score   support

          0       1.00      1.00      1.00        13
          1       1.00      1.00      1.00       249
          2       0.33      1.00      0.50         1
          3       0.93      0.93      0.93       286
          4       0.93      0.92      0.92       185
          5       0.96      0.93      0.94       231
          6       0.28      0.38      0.32        13
          7       0.00      0.00      0.00         0

avg / total       0.94      0.94      0.94       978

Train:
             precision    recall  f1-score   support

          0       1.00      1.00      1.00        73
          1       1.00      1.00      1.00       914
          2       1.00      1.00      1.00         6
          3       1.00      1.00      1.00      1147
          4       1.00      1.00      1.00       842
          5       1.00      1.00      1.00       866
          6       1.00      1.00      1.00        61
          7       1.00      1.00      1.00         5

avg / total       1.00      1.00      1.00      3914

==============================================
Date: Sun Jan  7 01:08:22 2018
Time taken to train: 1.642526388168335 seconds
Classifier: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.92      1.00      0.96        12
          1       1.00      0.96      0.98       258
          2       0.33      1.00      0.50         1
          3       0.91      0.90      0.90       291
          4       0.90      0.85      0.88       194
          5       0.93      0.96      0.95       217
          6       0.11      0.40      0.17         5
          7       0.00      0.00      0.00         0

avg / total       0.93      0.92      0.92       978

Train:
             precision    recall  f1-score   support

          0       1.00      1.00      1.00        73
          1       1.00      1.00      1.00       915
          2       1.00      1.00      1.00         6
          3       1.00      1.00      1.00      1147
          4       1.00      1.00      1.00       845
          5       1.00      1.00      1.00       865
          6       0.95      1.00      0.97        58
          7       1.00      1.00      1.00         5

avg / total       1.00      1.00      1.00      3914

==============================================
Date: Sun Jan  7 01:09:14 2018
Time taken to train: 50.08367967605591 seconds
Classifier: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       1.00      1.00      1.00        13
          1       0.08      0.91      0.15        23
          2       0.00      0.00      0.00         0
          3       0.54      0.98      0.70       158
          4       0.00      0.00      0.00         0
          5       1.00      0.29      0.45       784
          6       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.90      0.42      0.49       978

Train:
             precision    recall  f1-score   support

          0       1.00      1.00      1.00        73
          1       0.09      0.94      0.16        87
          2       0.00      0.00      0.00         0
          3       0.49      0.98      0.65       569
          4       0.00      0.00      0.00         0
          5       1.00      0.27      0.43      3185
          6       0.00      0.00      0.00         0
          7       0.00      0.00      0.00         0

avg / total       0.91      0.40      0.46      3914

==============================================
Date: Sun Jan  7 01:09:35 2018
Time taken to train: 12.007514238357544 seconds
Classifier: BaggingClassifier(base_estimator=None, bootstrap=True,
         bootstrap_features=False, max_features=1.0, max_samples=1.0,
         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,
         verbose=0, warm_start=False)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       1.00      1.00      1.00        13
          1       1.00      1.00      1.00       249
          2       0.33      1.00      0.50         1
          3       0.95      0.93      0.94       294
          4       0.93      0.94      0.94       182
          5       0.96      0.94      0.95       229
          6       0.39      0.78      0.52         9
          7       0.50      1.00      0.67         1

avg / total       0.96      0.95      0.95       978

Train:
             precision    recall  f1-score   support

          0       1.00      1.00      1.00        73
          1       1.00      1.00      1.00       914
          2       0.83      1.00      0.91         5
          3       1.00      0.99      1.00      1154
          4       0.99      1.00      0.99       839
          5       0.99      1.00      0.99       865
          6       0.97      1.00      0.98        59
          7       1.00      1.00      1.00         5

avg / total       1.00      1.00      1.00      3914

==============================================
Date: Sun Jan  7 01:37:04 2018
Time taken to train: 1649.332149028778 seconds
Classifier: GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              presort='auto', random_state=None, subsample=1.0, verbose=0,
              warm_start=False)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       1.00      1.00      1.00        13
          1       1.00      1.00      1.00       249
          2       0.33      1.00      0.50         1
          3       0.97      0.93      0.95       298
          4       0.93      0.93      0.93       183
          5       0.97      0.97      0.97       225
          6       0.44      0.89      0.59         9
          7       0.00      0.00      0.00         0

avg / total       0.97      0.96      0.96       978

Train:
             precision    recall  f1-score   support

          0       1.00      1.00      1.00        73
          1       1.00      1.00      1.00       914
          2       1.00      1.00      1.00         6
          3       1.00      0.98      0.99      1165
          4       0.98      1.00      0.99       829
          5       0.99      1.00      1.00       861
          6       1.00      1.00      1.00        61
          7       1.00      1.00      1.00         5

avg / total       0.99      0.99      0.99      3914

==============================================
Date: Mon Jan  8 19:33:18 2018
Time taken to train: 4.948707580566406 seconds
Classifier: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.94      0.95      0.95      8145
          1       0.76      0.74      0.75      1768

avg / total       0.91      0.91      0.91      9913

Train:
             precision    recall  f1-score   support

          0       1.00      1.00      1.00     12429
          1       1.00      1.00      1.00      2440

avg / total       1.00      1.00      1.00     14869

==============================================
Date: Mon Jan  8 19:33:29 2018
Time taken to train: 3.71863055229187 seconds
Classifier: GaussianNB(priors=None)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.85      0.89      0.87      7748
          1       0.52      0.42      0.46      2165

avg / total       0.77      0.79      0.78      9913

Train:
             precision    recall  f1-score   support

          0       0.90      1.00      0.95     11229
          1       1.00      0.67      0.80      3640

avg / total       0.93      0.92      0.91     14869

==============================================
Date: Mon Jan  8 19:35:34 2018
Time taken to train: 123.73520731925964 seconds
Classifier: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.92      0.93      0.92      8137
          1       0.65      0.63      0.64      1776

avg / total       0.87      0.87      0.87      9913

Train:
             precision    recall  f1-score   support

          0       1.00      1.00      1.00     12434
          1       1.00      1.00      1.00      2435

avg / total       1.00      1.00      1.00     14869

==============================================
Date: Mon Jan  8 19:35:58 2018
Time taken to train: 22.251198768615723 seconds
Classifier: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.99      0.85      0.92      9464
          1       0.20      0.77      0.32       449

avg / total       0.95      0.85      0.89      9913

Train:
             precision    recall  f1-score   support

          0       1.00      0.99      0.99     12570
          1       0.94      1.00      0.97      2299

avg / total       0.99      0.99      0.99     14869

==============================================
Date: Mon Jan  8 19:44:44 2018
Time taken to train: 513.0815985202789 seconds
Classifier: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.95      0.93      0.94      8436
          1       0.64      0.75      0.69      1477

avg / total       0.91      0.90      0.90      9913

Train:
             precision    recall  f1-score   support

          0       0.96      0.95      0.96     12505
          1       0.76      0.78      0.77      2364

avg / total       0.93      0.92      0.93     14869

==============================================
Date: Mon Jan  8 19:49:08 2018
Time taken to train: 181.0506947040558 seconds
Classifier: BaggingClassifier(base_estimator=None, bootstrap=True,
         bootstrap_features=False, max_features=1.0, max_samples=1.0,
         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,
         verbose=0, warm_start=False)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.95      0.92      0.94      8455
          1       0.61      0.72      0.66      1458

avg / total       0.90      0.89      0.90      9913

Train:
             precision    recall  f1-score   support

          0       1.00      0.99      1.00     12480
          1       0.97      0.99      0.98      2389

avg / total       0.99      0.99      0.99     14869

==============================================
Date: Mon Jan  8 20:17:08 2018
Time taken to train: 66.57974147796631 seconds
Classifier: GridSearchCV(cv=None, error_score='raise',
       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False),
       fit_params=None, iid=True, n_jobs=1,
       param_grid={'penalty': ['l2', 'l1'], 'max_iter': [10, 100, 1000, 10000]},
       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
       scoring='accuracy', verbose=10)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.95      0.96      0.95      8109
          1       0.80      0.76      0.78      1804

avg / total       0.92      0.92      0.92      9913

Train:
             precision    recall  f1-score   support

          0       1.00      1.00      1.00     12426
          1       0.99      0.99      0.99      2443

avg / total       1.00      1.00      1.00     14869

==============================================
Date: Mon Jan  8 20:22:41 2018
Time taken to train: 74.85789251327515 seconds
Classifier: GridSearchCV(cv=None, error_score='raise',
       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False),
       fit_params=None, iid=True, n_jobs=1,
       param_grid={'penalty': ['l2', 'l1'], 'max_iter': [10, 100, 1000, 10000]},
       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
       scoring='accuracy', verbose=10)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.95      0.96      0.95      8142
          1       0.79      0.77      0.78      1771

avg / total       0.92      0.92      0.92      9913

Train:
             precision    recall  f1-score   support

          0       1.00      1.00      1.00     12425
          1       0.99      0.99      0.99      2444

avg / total       1.00      1.00      1.00     14869

==============================================
Date: Mon Jan  8 20:28:52 2018
Time taken to train: 26.22763466835022 seconds
Classifier: GridSearchCV(cv=<generator object _BaseKFold.split at 0x000001E2084006D0>,
       error_score='raise',
       estimator=Pipeline(memory=None,
     steps=[('select', SelectFromModel(estimator=LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, wa...ty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))]),
       fit_params=None, iid=True, n_jobs=1, param_grid=[{}],
       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
       scoring=None, verbose=2)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.85      0.99      0.91      7028
          1       0.96      0.57      0.72      2885

avg / total       0.88      0.87      0.86      9913

Train:
             precision    recall  f1-score   support

          0       0.89      0.99      0.94     11118
          1       0.97      0.63      0.76      3751

avg / total       0.91      0.90      0.89     14869

==================================================
Date: Thu Jan 25 23:49:59 2018
Time taken to train: 25.70432710647583 seconds
Classifier: GridSearchCV(cv=<generator object _BaseKFold.split at 0x0000017002F89F10>,
       error_score='raise',
       estimator=Pipeline(memory=None,
     steps=[('select', SelectFromModel(estimator=LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, wa...ty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))]),
       fit_params=None, iid=True, n_jobs=1, param_grid=[{}],
       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
       scoring=None, verbose=2)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.85      0.99      0.91      7028
          1       0.96      0.57      0.72      2885

avg / total       0.88      0.87      0.86      9913

Train:
             precision    recall  f1-score   support

          0       0.89      0.99      0.94     11118
          1       0.97      0.63      0.76      3751

avg / total       0.91      0.90      0.89     14869

==============================================
Date: Fri Jan 26 00:20:19 2018
Time taken to train: 27.1200692653656 seconds
Classifier: GridSearchCV(cv=<generator object _BaseKFold.split at 0x000002612015A200>,
       error_score='raise',
       estimator=Pipeline(memory=None,
     steps=[('select', SelectFromModel(estimator=LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, wa...ty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))]),
       fit_params=None, iid=True, n_jobs=1, param_grid=[{}],
       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
       scoring=None, verbose=2)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.85      0.99      0.91      7028
          1       0.96      0.57      0.72      2885

avg / total       0.88      0.87      0.86      9913

Train:
             precision    recall  f1-score   support

          0       0.89      0.99      0.94     11118
          1       0.97      0.63      0.76      3751

avg / total       0.91      0.90      0.89     14869

==============================================
Date: Fri Jan 26 00:22:32 2018
Time taken to train: 25.70075750350952 seconds
Classifier: GridSearchCV(cv=<generator object _BaseKFold.split at 0x00000211D378A200>,
       error_score='raise',
       estimator=Pipeline(memory=None,
     steps=[('select', SelectFromModel(estimator=LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, wa...ty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))]),
       fit_params=None, iid=True, n_jobs=1, param_grid=[{}],
       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
       scoring=None, verbose=2)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.85      0.99      0.91      7028
          1       0.96      0.57      0.72      2885

avg / total       0.88      0.87      0.86      9913

Train:
             precision    recall  f1-score   support

          0       0.89      0.99      0.94     11118
          1       0.97      0.63      0.76      3751

avg / total       0.91      0.90      0.89     14869

==============================================
Date: Sat Jan 27 00:19:14 2018
Time taken to train: 15.518726110458374 seconds
Classifier: GridSearchCV(cv=<generator object _BaseKFold.split at 0x000001F2D3EFB1A8>,
       error_score='raise',
       estimator=Pipeline(memory=None,
     steps=[('select', SelectFromModel(estimator=LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, wa...ty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))]),
       fit_params=None, iid=True, n_jobs=1, param_grid=[{}],
       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
       scoring=None, verbose=2)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.84      0.99      0.91      6980
          1       0.96      0.57      0.71      2933

avg / total       0.88      0.87      0.85      9913

Train:
             precision    recall  f1-score   support

          0       0.89      0.99      0.94     11081
          1       0.97      0.63      0.76      3788

avg / total       0.91      0.90      0.89     14869

==============================================
Date: Sat Jan 27 00:28:04 2018
Time taken to train: 10.36238694190979 seconds
Classifier: GridSearchCV(cv=<generator object _BaseKFold.split at 0x0000015374659200>,
       error_score='raise',
       estimator=Pipeline(memory=None,
     steps=[('select', SelectFromModel(estimator=LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, wa...ty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))]),
       fit_params=None, iid=True, n_jobs=1, param_grid=[{}],
       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
       scoring=None, verbose=2)
---------------------------------
Test:
             precision    recall  f1-score   support

          0       0.84      0.99      0.91      6951
          1       0.97      0.56      0.71      2962

avg / total       0.88      0.86      0.85      9913

Train:
             precision    recall  f1-score   support

          0       0.89      0.99      0.94     11095
          1       0.97      0.63      0.76      3774

avg / total       0.91      0.90      0.89     14869

=======================