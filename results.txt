Date: Sun Dec 24 19:00:56 2017
Time taken to train: 1.7427499294281006 seconds
Classifier: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
---------------------------------
Test Accuracy   : 0.9147583980631494
Train Accuracy  : 0.9605891452014258
---------------------------------
Test precision  : 0.592069761981788
Train precision : 0.7939219184152745
---------------------------------
Test recall     : 0.6136890951276102
Train recall    : 0.8085280852808528
---------------------------------
Test f1         : 0.7146234380276932
Train f1        : 0.8706401766004417
==============================================
Date: Sun Dec 24 19:01:08 2017
Time taken to train: 3.6305489540100098 seconds
Classifier: GaussianNB(priors=None)
---------------------------------
Test Accuracy   : 0.7622314132956723
Train Accuracy  : 0.894814715179232
---------------------------------
Test precision  : 0.2904072956848476
Train precision : 0.6092930302273295
---------------------------------
Test recall     : 0.570185614849188
Train recall    : 1.0
---------------------------------
Test f1         : 0.4547767753874624
Train f1        : 0.7572182552002483
==============================================
Date: Sun Dec 24 19:02:25 2017
Time taken to train: 75.1136999130249 seconds
Classifier: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
---------------------------------
Test Accuracy   : 0.8866135377786745
Train Accuracy  : 0.9995964758894343
---------------------------------
Test precision  : 0.518312162347073
Train precision : 0.9979434995103197
---------------------------------
Test recall     : 0.701276102088167
Train recall    : 0.997539975399754
---------------------------------
Test f1         : 0.6826651609260305
Train f1        : 0.9987684729064039
==============================================
Date: Sun Dec 24 19:02:49 2017
Time taken to train: 23.206650018692017 seconds
Classifier: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
---------------------------------
Test Accuracy   : 0.8648239685261777
Train Accuracy  : 0.9906516914385635
---------------------------------
Test precision  : 0.3589594765723934
Train precision : 0.9519605986920584
---------------------------------
Test recall     : 0.2906032482598608
Train recall    : 0.9454694546945469
---------------------------------
Test f1         : 0.42783945345858243
Train f1        : 0.970743001473374
==============================================
Date: Sun Dec 24 19:10:04 2017
Time taken to train: 423.68222999572754 seconds
Classifier: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
---------------------------------
Test Accuracy   : 0.9081004741248865
Train Accuracy  : 0.9387315892124555
---------------------------------
Test precision  : 0.5944695416884387
Train precision : 0.6917989011197566
---------------------------------
Test recall     : 0.7679814385150812
Train recall    : 0.8118081180811808
---------------------------------
Test f1         : 0.7440292216914863
Train f1        : 0.8129747485115992
==============================================
Date: Sun Dec 24 19:13:51 2017
Time taken to train: 132.40489864349365 seconds
Classifier: BaggingClassifier(base_estimator=None, bootstrap=True,
         bootstrap_features=False, max_features=1.0, max_samples=1.0,
         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,
         verbose=0, warm_start=False)
---------------------------------
Test Accuracy   : 0.9140522546151518
Train Accuracy  : 0.9948214405810747
---------------------------------
Test precision  : 0.5958377127203071
Train precision : 0.9729529161301506
---------------------------------
Test recall     : 0.6722737819025522
Train recall    : 0.972529725297253
---------------------------------
Test f1         : 0.7312302839116719
Train f1        : 0.9840282099149555
==============================================
Date: Sun Dec 24 19:45:04 2017
Time taken to train: 1871.2150180339813 seconds
Classifier: GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              presort='auto', random_state=None, subsample=1.0, verbose=0,
              warm_start=False)
---------------------------------
Test Accuracy   : 0.9054776556037526
Train Accuracy  : 0.9320061873696953
---------------------------------
Test precision  : 0.549910674619833
Train precision : 0.6487247512518167
---------------------------------
Test recall     : 0.5678654292343387
Train recall    : 0.6514965149651496
---------------------------------
Test f1         : 0.6763385146804836
Train f1        : 0.7586536166149439
==============================================
Date: Sun Dec 24 19:55:11 2017
Time taken to train: 604.7098784446716 seconds
Classifier: GridSearchCV(cv=None, error_score='raise',
       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False),
       fit_params=None, iid=True, n_jobs=1,
       param_grid={'n_estimators': [10, 30, 50, 100], 'criterion': ['gini', 'entropy'], 'n_jobs': [-1]},
       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,
       scoring=None, verbose=0)
---------------------------------
Test Accuracy   : 0.8849994956118229
Train Accuracy  : 0.9995964758894343
---------------------------------
Test precision  : 0.4510583916810949
Train precision : 0.9977432503852952
---------------------------------
Test recall     : 0.39675174013921116
Train recall    : 0.998769987699877
---------------------------------
Test f1         : 0.5454545454545454
Train f1        : 0.998769987699877
==============================================
Date: Mon Dec 25 19:38:33 2017
Time taken to train: 2.6165318489074707 seconds
Classifier: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
---------------------------------
Test Accuracy   : 0.9155654191465752
Train Accuracy  : 0.9603201291277154
---------------------------------
Test precision  : 0.5958487396888617
Train precision : 0.7922245042038072
---------------------------------
Test recall     : 0.6189095127610209
Train recall    : 0.8134481344813448
---------------------------------
Test f1         : 0.7182766745203635
Train f1        : 0.8705572619569987
==============================================
Date: Mon Dec 25 19:38:46 2017
Time taken to train: 4.181003093719482 seconds
Classifier: GaussianNB(priors=None)
---------------------------------
Test Accuracy   : 0.7906789064864319
Train Accuracy  : 0.9020781491694129
---------------------------------
Test precision  : 0.3289059122814015
Train precision : 0.6261874197689346
---------------------------------
Test recall     : 0.6090487238979119
Train recall    : 1.0
---------------------------------
Test f1         : 0.502994011976048
Train f1        : 0.7701294600568361
==============================================
Date: Mon Dec 25 19:40:23 2017
Time taken to train: 95.01912760734558 seconds
Classifier: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
---------------------------------
Test Accuracy   : 0.8894381115706648
Train Accuracy  : 0.9997309839262896
---------------------------------
Test precision  : 0.525300447035909
Train precision : 0.9986289996735465
---------------------------------
Test recall     : 0.7001160092807425
Train recall    : 0.998359983599836
---------------------------------
Test f1         : 0.6877492877492878
Train f1        : 0.9991793188346327
==============================================
Date: Mon Dec 25 19:40:52 2017
Time taken to train: 27.684523820877075 seconds
Classifier: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
---------------------------------
Test Accuracy   : 0.8606879854736205
Train Accuracy  : 0.9899118972358598
---------------------------------
Test precision  : 0.34085012536307835
Train precision : 0.948190378313918
---------------------------------
Test recall     : 0.2708816705336427
Train recall    : 0.940959409594096
---------------------------------
Test f1         : 0.4034557235421166
Train f1        : 0.9683544303797469
==============================================
Date: Mon Dec 25 19:50:44 2017
Time taken to train: 578.9586148262024 seconds
Classifier: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
---------------------------------
Test Accuracy   : 0.9160698073237163
Train Accuracy  : 0.9367139686596274
---------------------------------
Test precision  : 0.6092121656878351
Train precision : 0.6788661408655886
---------------------------------
Test recall     : 0.7117169373549884
Train recall    : 0.7761377613776138
---------------------------------
Test f1         : 0.7468046256847231
Train f1        : 0.8009308229320923
==============================================
Date: Mon Dec 25 19:54:47 2017
Time taken to train: 139.95822143554688 seconds
Classifier: BaggingClassifier(base_estimator=None, bootstrap=True,
         bootstrap_features=False, max_features=1.0, max_samples=1.0,
         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,
         verbose=0, warm_start=False)
---------------------------------
Test Accuracy   : 0.9118329466357309
Train Accuracy  : 0.9950904566547851
---------------------------------
Test precision  : 0.5909335600427763
Train precision : 0.9738239761769751
---------------------------------
Test recall     : 0.691415313225058
Train recall    : 0.977449774497745
---------------------------------
Test f1         : 0.7317372621240025
Train f1        : 0.9849204709770709
==============================================
Date: Mon Dec 25 20:28:01 2017
Time taken to train: 1992.089189529419 seconds
Classifier: GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              presort='auto', random_state=None, subsample=1.0, verbose=0,
              warm_start=False)
---------------------------------
Test Accuracy   : 0.9059820437808938
Train Accuracy  : 0.9320061873696953
---------------------------------
Test precision  : 0.5521145742705567
Train precision : 0.6487322206733368
---------------------------------
Test recall     : 0.5696055684454756
Train recall    : 0.6531365313653137
---------------------------------
Test f1         : 0.6781767955801106
Train f1        : 0.7591136526090064
==============================================
Date: Mon Dec 25 20:39:56 2017
Time taken to train: 712.3323681354523 seconds
Classifier: GridSearchCV(cv=None, error_score='raise',
       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False),
       fit_params=None, iid=True, n_jobs=1,
       param_grid={'n_estimators': [10, 30, 50, 100], 'criterion': ['gini', 'entropy'], 'n_jobs': [-1]},
       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,
       scoring=None, verbose=0)
---------------------------------
Test Accuracy   : 0.8778371834964188
Train Accuracy  : 0.9997309839262896
---------------------------------
Test precision  : 0.4170530963846772
Train precision : 0.9984951640501395
---------------------------------
Test recall     : 0.339907192575406
Train recall    : 0.999179991799918
---------------------------------
Test f1         : 0.49181703734788085
Train f1        : 0.999179991799918
==============================================
Date: Fri Dec 29 00:26:05 2017
Time taken to train: 3.3784987926483154 seconds
Classifier: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
---------------------------------
Test Accuracy   : 0.915464541511147
Train Accuracy  : 0.960387383146143
---------------------------------
Test precision  : 0.5954244030436593
Train precision : 0.7925473763634024
---------------------------------
Test recall     : 0.6189095127610209
Train recall    : 0.8142681426814268
---------------------------------
Test f1         : 0.7180349932705249
Train f1        : 0.8708616531462398
==============================================
Date: Fri Dec 29 00:26:17 2017
Time taken to train: 3.6360015869140625 seconds
Classifier: GaussianNB(priors=None)
---------------------------------
Test Accuracy   : 0.7910824170281449
Train Accuracy  : 0.9013383549667092
---------------------------------
Test precision  : 0.3326335819170074
Train precision : 0.6244239631336406
---------------------------------
Test recall     : 0.6194895591647331
Train recall    : 1.0
---------------------------------
Test f1         : 0.5077252198716425
Train f1        : 0.7687943262411348
==============================================
Date: Fri Dec 29 00:27:25 2017
Time taken to train: 67.26507043838501 seconds
Classifier: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
---------------------------------
Test Accuracy   : 0.8911530313729447
Train Accuracy  : 0.9997309839262896
---------------------------------
Test precision  : 0.5356301038547558
Train precision : 0.9986289996735465
---------------------------------
Test recall     : 0.7221577726218097
Train recall    : 0.998359983599836
---------------------------------
Test f1         : 0.6976744186046511
Train f1        : 0.9991793188346327
==============================================
Date: Fri Dec 29 00:27:50 2017
Time taken to train: 23.15856146812439 seconds
Classifier: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
---------------------------------
Test Accuracy   : 0.8705739937455866
Train Accuracy  : 0.9913914856412671
---------------------------------
Test precision  : 0.3857328658022334
Train precision : 0.9558618023135825
---------------------------------
Test recall     : 0.32830626450116007
Train recall    : 0.949159491594916
---------------------------------
Test f1         : 0.4687370600414079
Train f1        : 0.9730979403110551
==============================================
Date: Fri Dec 29 00:36:47 2017
Time taken to train: 524.8418583869934 seconds
Classifier: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
---------------------------------
Test Accuracy   : 0.9160698073237163
Train Accuracy  : 0.9367139686596274
---------------------------------
Test precision  : 0.6092121656878351
Train precision : 0.6788661408655886
---------------------------------
Test recall     : 0.7117169373549884
Train recall    : 0.7761377613776138
---------------------------------
Test f1         : 0.7468046256847231
Train f1        : 0.8009308229320923
==============================================
Date: Fri Dec 29 00:40:19 2017
Time taken to train: 122.81123900413513 seconds
Classifier: BaggingClassifier(base_estimator=None, bootstrap=True,
         bootstrap_features=False, max_features=1.0, max_samples=1.0,
         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,
         verbose=0, warm_start=False)
---------------------------------
Test Accuracy   : 0.9094118833854534
Train Accuracy  : 0.9956957428206336
---------------------------------
Test precision  : 0.5807547343889208
Train precision : 0.9767868239899777
---------------------------------
Test recall     : 0.6809744779582366
Train recall    : 0.981959819598196
---------------------------------
Test f1         : 0.7233518176216881
Train f1        : 0.9868149979398434
==============================================
Date: Fri Dec 29 01:08:10 2017
Time taken to train: 1669.642015695572 seconds
Classifier: GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              presort='auto', random_state=None, subsample=1.0, verbose=0,
              warm_start=False)
---------------------------------
Test Accuracy   : 0.9052759003328962
Train Accuracy  : 0.932073441388123
---------------------------------
Test precision  : 0.5488677459563438
Train precision : 0.6490653998433106
---------------------------------
Test recall     : 0.5655452436194895
Train recall    : 0.6523165231652317
---------------------------------
Test f1         : 0.6749740394600208
Train f1        : 0.7590648854961833
==============================================
Date: Fri Dec 29 01:16:17 2017
Time taken to train: 484.9506561756134 seconds
Classifier: GridSearchCV(cv=None, error_score='raise',
       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False),
       fit_params=None, iid=True, n_jobs=1,
       param_grid={'n_estimators': [10, 30, 50, 100], 'criterion': ['gini', 'entropy'], 'n_jobs': [-1]},
       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,
       scoring=None, verbose=0)
---------------------------------
Test Accuracy   : 0.8731968122667205
Train Accuracy  : 0.9990584437420136
---------------------------------
Test precision  : 0.39602723080109936
Train precision : 0.995134413773513
---------------------------------
Test recall     : 0.3254060324825986
Train recall    : 0.994669946699467
---------------------------------
Test f1         : 0.47162673392181587
Train f1        : 0.9971228935470612
==============================================
Date: Sat Dec 30 19:09:47 2017
Time taken to train: 16.04547643661499 seconds
Classifier: GridSearchCV(cv=<generator object _BaseKFold.split at 0x000001F4FFC4C150>,
       error_score='raise',
       estimator=Pipeline(memory=None,
     steps=[('select', SelectFromModel(estimator=LogisticRegression(C=0.01, class_weight='balanced', dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, wa...ty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))]),
       fit_params=None, iid=True, n_jobs=1, param_grid=[{}],
       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,
       scoring=None, verbose=2)
---------------------------------
Test Accuracy   : 0.6716432966811258
Train Accuracy  : 0.7463178424910888
---------------------------------
Test precision  : 0.3259025852963107
Train precision : 0.37682922208885117
---------------------------------
Test recall     : 0.9263341067285383
Train recall    : 0.949159491594916
---------------------------------
Test f1         : 0.49527058458675766
Train f1        : 0.5510592716019995